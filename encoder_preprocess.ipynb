{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3119f7ae",
   "metadata": {},
   "source": [
    "### writing to  s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c520972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "client = boto3.client(\"s3\")\n",
    "\n",
    "def to_s3_npy(data: np.array, s3_uri: str):\n",
    "    # s3_uri looks like f\"s3://{BUCKET_NAME}/{KEY}\"\n",
    "    bytes_ = BytesIO()\n",
    "    np.save(bytes_, data, allow_pickle=True)\n",
    "    bytes_.seek(0)\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    client.upload_fileobj(\n",
    "        Fileobj=bytes_, Bucket=parsed_s3.netloc, Key=parsed_s3.path[1:]\n",
    "    )\n",
    "    return True\n",
    "\n",
    "def from_s3_npy(s3_uri: str):\n",
    "    bytes_ = BytesIO()\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    client.download_fileobj(\n",
    "        Fileobj=bytes_, Bucket=parsed_s3.netloc, Key=parsed_s3.path[1:]\n",
    "    )\n",
    "    bytes_.seek(0)\n",
    "    return np.load(bytes_, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89f69c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/encoder_librispeech_valid.npz\", allow_pickle=True)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc394b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_s3_npy(data, \"s3://rtvc-data/preprocessed/encoder_librispeech_valid.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed0f59",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b373b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import librosa\n",
    "import webrtcvad\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from scipy.ndimage.morphology import binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d28fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loadbar(iteration, total, prefix=\"\", suffix=\"\", decimal=0, \n",
    "            length=100, fill=\"=\", extras=\"\"):\n",
    "    per_val = iteration*100/float(total)\n",
    "    \n",
    "    percent = (\"{0:.\" + str(decimal) + \"f}\").format(per_val)   \n",
    "    cur_percent = ( ' ' * (3-len(str(round(per_val)))) + percent)\n",
    "    \n",
    "    filledLen = int(length * iteration//total)\n",
    "    if per_val == 100:\n",
    "        bar = fill * filledLen + \".\" * (length - filledLen)\n",
    "    else:\n",
    "        bar = fill * filledLen + \">\" + \".\" * (length - filledLen - 1)\n",
    "        \n",
    "    print(f\"\\r{prefix} [{bar}] {cur_percent}% {suffix}\", end=\"\\r\")\n",
    "    if iteration == total: \n",
    "        print(f\"\\r{prefix} [{bar}] {cur_percent}% {suffix} {extras}\", end=\"\\n\")\n",
    "        \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3475d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARG_dbFS = -30\n",
    "TARG_FS = 16000 \n",
    "INT16_MAX = (2**15) - 1\n",
    "\n",
    "VAD_WNDW_LEN = 30  \n",
    "VAD_WNDW_AVG_WIDTH = 8\n",
    "VAD_MAX_SILENCE_LEN = 6\n",
    "\n",
    "MEL_WNDW_LEN = 25  \n",
    "MEL_WNDW_STP = 10  \n",
    "MEL_N_CHANNELS = 40 \n",
    "\n",
    "PAR_N_FRAMES=160\n",
    "\n",
    "AUDIO_RE = \"[fw][la][av]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783114d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = {\n",
    "    \"LibriSpeech\": \".flac\",\n",
    "    \"LibriTTS\": \".wav\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b310d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print = lambda val, total, substitute=0: f'{substitute}' * (len(str(total))-len(str(val))) + str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d36b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(wav, target_dBFS=TARG_dbFS, increase_only=False, decrease_only=False):\n",
    "    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n",
    "    if (dBFS_change < 0 and increase_only) or (dBFS_change > 0 and decrease_only):\n",
    "        return wav\n",
    "    return wav * (10 ** (dBFS_change / 20))\n",
    "\n",
    "def moving_average(array, width):\n",
    "    array_padded = np.concatenate((np.zeros((width - 1) // 2), array, np.zeros(width // 2)))\n",
    "    ret = np.cumsum(array_padded, dtype=float)\n",
    "    ret[width:] = ret[width:] - ret[:-width]\n",
    "    return ret[width - 1:] / width\n",
    "\n",
    "def trim_long_silences(wav, sampling_rate=TARG_FS):\n",
    "    samples_per_window = (VAD_WNDW_LEN * sampling_rate) // 1000\n",
    "    wav = wav[:len(wav) - (len(wav) % samples_per_window)]\n",
    "    pcm_wave = struct.pack(\"%dh\" % len(wav), *(np.round(wav * INT16_MAX)).astype(np.int16))\n",
    "\n",
    "    voice_flags = []\n",
    "    vad = webrtcvad.Vad(mode=3)\n",
    "    for window_start in range(0, len(wav), samples_per_window):\n",
    "        window_end = window_start + samples_per_window\n",
    "        voice_flags.append(vad.is_speech(pcm_wave[window_start * 2:window_end * 2], sample_rate=sampling_rate))\n",
    "    audio_mask = moving_average(voice_flags, VAD_WNDW_AVG_WIDTH)\n",
    "    audio_mask = np.round(audio_mask).astype(np.bool_)\n",
    "    audio_mask = binary_dilation(audio_mask, np.ones(VAD_MAX_SILENCE_LEN + 1))\n",
    "    audio_mask = np.repeat(audio_mask, samples_per_window)\n",
    "    return wav[audio_mask == True]\n",
    "\n",
    "def load_audio(file_path):\n",
    "    arr, _ = librosa.load(file_path) \n",
    "    return arr\n",
    "\n",
    "def preprocess_data(arr):\n",
    "        return trim_long_silences(normalize_volume(arr))\n",
    "\n",
    "def generate_frames(preprocessed_wav, sampling_rate=TARG_FS):\n",
    "    frames = librosa.feature.melspectrogram(\n",
    "    y=preprocessed_wav,\n",
    "    sr=sampling_rate,\n",
    "    n_fft=int(sampling_rate * MEL_WNDW_LEN / 1000),\n",
    "    hop_length=int(sampling_rate * MEL_WNDW_STP / 1000),\n",
    "    n_mels=MEL_N_CHANNELS\n",
    "    )\n",
    "    return frames.astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4860a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 5536 - File [010/010] [==================================================] 100%  \n",
      "Speaker 1993 - File [010/010] [==================================================] 100%  \n",
      "Speaker 0174 - File [010/010] [==================================================] 100%  \n",
      "Speaker 2803 - File [010/010] [==================================================] 100%  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(dataset=\"LibriSpeech\", split=\"dev-clean\", limit_speakers=None, limit_files=None):\n",
    "    data = []\n",
    "    for spath in glob(f\"../data/{dataset}/{split}/*\")[:limit_speakers]:\n",
    "        sid = spath.split(\"/\")[-1]\n",
    "        fpaths = glob(f\"{spath}/*/*{extensions[dataset]}\")\n",
    "        \n",
    "        i = 0\n",
    "        size = len(fpaths) if limit_files==None else limit_files\n",
    "        p = f\"Speaker {pretty_print(int(sid), '0000')} - File [{pretty_print(int(pretty_print(i, size)), '000')}/{pretty_print(size, '000')}]\"\n",
    "        loadbar(i, size, p, length=50)\n",
    "        for fpath in fpaths[:limit_files]:           \n",
    "            fid = fpath.split(\"/\")[-1].split(\".\")[0]\n",
    "            arr = generate_frames(preprocess_data(load_audio(fpath)))\n",
    "            if arr.shape[0] >= PAR_N_FRAMES: data.append((fid, sid, arr))\n",
    "            \n",
    "            p = f\"Speaker {pretty_print(int(sid), '0000')} - File [{pretty_print(int(pretty_print(i+1, size)), '000')}/{pretty_print(size, '000')}]\"\n",
    "            loadbar(i+1, size, p, length=50)\n",
    "            i += 1\n",
    "\n",
    "    return np.array(data, dtype=object)\n",
    "\n",
    "tmp = preprocess(limit_speakers=4, limit_files=10)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63697e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LibriSpeech: dev-clean\n",
    "# data = preprocess()\n",
    "# data.shape\n",
    "\n",
    "# np.savez(\"data/encoder_librispeech_valid.npz\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf6757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54387933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LibriSpeech: train-clean-100\n",
    "# data = preprocess(split=\"train-clean-100\")\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcda51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
