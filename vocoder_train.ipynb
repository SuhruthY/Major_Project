{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd585efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "486b89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loadbar(iteration, total, prefix=\"\", suffix=\"\", decimal=0, \n",
    "            length=100, fill=\"=\", extras=\"\"):\n",
    "    per_val = iteration*100/float(total)\n",
    "    \n",
    "    percent = (\"{0:.\" + str(decimal) + \"f}\").format(per_val)   \n",
    "    cur_percent = ( ' ' * (3-len(str(round(per_val)))) + percent)\n",
    "    \n",
    "    filledLen = int(length * iteration//total)\n",
    "    if per_val == 100:\n",
    "        bar = fill * filledLen + \".\" * (length - filledLen)\n",
    "    else:\n",
    "        bar = fill * filledLen + \">\" + \".\" * (length - filledLen - 1)\n",
    "        \n",
    "    print(f\"\\r{prefix} [{bar}] {cur_percent}% {suffix}\", end=\"\\r\")\n",
    "    if iteration == total: \n",
    "        print(f\"\\r{prefix} [{bar}] {cur_percent}% {suffix} {extras}\", end=\"\\n\")\n",
    "        \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5037b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33ee825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    # from synthesizer\n",
    "    hop_length = 200\n",
    "    mel_max_abs_value = 4.,\n",
    "    preemphasis = 0.97\n",
    "    apply_preemphasis = True\n",
    "    num_mels = 80\n",
    "    sample_rate = 16000\n",
    "    \n",
    "    bits = 9 \n",
    "    mu_law = True\n",
    "   \n",
    "    voc_pad = 2 \n",
    "    voc_lr = 1e-4\n",
    "    voc_batch_size = 100\n",
    "    voc_mode = 'RAW'\n",
    "    voc_rnn_dims = 512\n",
    "    voc_fc_dims = 512\n",
    "    voc_res_blocks = 10\n",
    "    voc_compute_dims = 128\n",
    "    voc_res_out_dims = 128\n",
    "    voc_seq_len = hop_length * 5\n",
    "    voc_upsample_factors = (5, 5, 8)\n",
    "    \n",
    "    \n",
    "hparams = Hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e4ca7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print = lambda val, total, substitute=0: f'{substitute}' * (len(str(total))-len(str(val))) + str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae995cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mu_law(x, mu) :\n",
    "    mu = mu - 1\n",
    "    fx = np.sign(x) * np.log(1 + mu * np.abs(x)) / np.log(1 + mu)\n",
    "    return np.floor((fx + 1) / 2 * mu + 0.5)\n",
    "\n",
    "def float_2_label(x, bits) :\n",
    "    assert abs(x).max() <= 1.0\n",
    "    x = (x + 1.) * (2**bits - 1) / 2\n",
    "    return x.clip(0, 2**bits - 1)\n",
    "\n",
    "def label_2_float(x, bits) :\n",
    "    return 2 * x / (2**bits - 1.) - 1.\n",
    "\n",
    "def pre_emphasis(x):\n",
    "    return lfilter([1, -hparams.preemphasis], [1], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0f13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2333, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/vocoder_librispeech_valid.npz\", allow_pickle=True)[\"arr_0\"]\n",
    "data = pd.DataFrame(data)[[3, 4]].to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "448ba11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 742), (148400,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VocoderDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):  \n",
    "        wav, mel = self.data[index]\n",
    "        \n",
    "        mel = mel.T.astype(np.float32) / hparams.mel_max_abs_value\n",
    "        \n",
    "        if hparams.apply_preemphasis: wav = pre_emphasis(wav)\n",
    "        wav = np.clip(wav, -1, 1)\n",
    "        \n",
    "        r_pad =  (len(wav) // hparams.hop_length + 1) * hparams.hop_length - len(wav)\n",
    "        wav = np.pad(wav, (0, r_pad), mode='constant')\n",
    "        assert len(wav) >= mel.shape[1] * hparams.hop_length\n",
    "        wav = wav[:mel.shape[1] * hparams.hop_length]\n",
    "        assert len(wav) % hparams.hop_length == 0\n",
    "        \n",
    "        # Quantize the wav\n",
    "        if hparams.voc_mode == 'RAW':\n",
    "            if hparams.mu_law:\n",
    "                quant = encode_mu_law(wav, mu=2 ** hparams.bits)\n",
    "            else:\n",
    "                quant = float_2_label(wav, bits=hparams.bits)\n",
    "        elif hparams.voc_mode == 'MOL':\n",
    "            quant = float_2_label(wav, bits=16)\n",
    "            \n",
    "        return mel.astype(np.float32), quant.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "tmp =  VocoderDataset(data)\n",
    "\n",
    "# tmp\n",
    "\n",
    "x, y = tmp.__getitem__(1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa0351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_vocoder(batch):\n",
    "    mel_win = hparams.voc_seq_len // hparams.hop_length + 2 * hparams.voc_pad\n",
    "    max_offsets = [x[0].shape[-1] -2 - (mel_win + 2 * hparams.voc_pad) for x in batch]\n",
    "    mel_offsets = [np.random.randint(0, offset) for offset in max_offsets]\n",
    "    sig_offsets = [(offset + hparams.voc_pad) * hparams.hop_length for offset in mel_offsets]\n",
    "\n",
    "    mels = [x[0][:, mel_offsets[i]:mel_offsets[i] + mel_win] for i, x in enumerate(batch)]\n",
    "\n",
    "    labels = [x[1][sig_offsets[i]:sig_offsets[i] + hparams.voc_seq_len + 1] for i, x in enumerate(batch)]\n",
    "\n",
    "    mels = np.stack(mels).astype(np.float32)\n",
    "    labels = np.stack(labels).astype(np.int64)\n",
    "\n",
    "    mels = torch.tensor(mels)\n",
    "    labels = torch.tensor(labels).long()\n",
    "\n",
    "    x = labels[:, :hparams.voc_seq_len]\n",
    "    y = labels[:, 1:]\n",
    "\n",
    "    bits = 16 if hparams.voc_mode == 'MOL' else hparams.bits\n",
    "\n",
    "    x = label_2_float(x.float(), bits)\n",
    "\n",
    "    if hparams.voc_mode == 'MOL' :\n",
    "        y = label_2_float(y.float(), bits)\n",
    "\n",
    "    return x, y, mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78a41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(dims, dims, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(dims, dims, kernel_size=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(dims)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class MelResNet(nn.Module):\n",
    "    def __init__(self, res_blocks, in_dims, compute_dims, res_out_dims, pad):\n",
    "        super().__init__()\n",
    "        k_size = pad * 2 + 1\n",
    "        self.conv_in = nn.Conv1d(in_dims, compute_dims, kernel_size=k_size, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm1d(compute_dims)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(res_blocks):\n",
    "            self.layers.append(ResBlock(compute_dims))\n",
    "        self.conv_out = nn.Conv1d(compute_dims, res_out_dims, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.relu(x)\n",
    "        for f in self.layers: x = f(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Stretch2d(nn.Module):\n",
    "    def __init__(self, x_scale, y_scale):\n",
    "        super().__init__()\n",
    "        self.x_scale = x_scale\n",
    "        self.y_scale = y_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.unsqueeze(-1).unsqueeze(3)\n",
    "        x = x.repeat(1, 1, 1, self.y_scale, 1, self.x_scale)\n",
    "        return x.view(b, c, h * self.y_scale, w * self.x_scale)\n",
    "\n",
    "\n",
    "class UpsampleNetwork(nn.Module):\n",
    "    def __init__(self, feat_dims, upsample_scales, compute_dims,\n",
    "                 res_blocks, res_out_dims, pad):\n",
    "        super().__init__()\n",
    "        total_scale = np.cumproduct(upsample_scales)[-1]\n",
    "        self.indent = pad * total_scale\n",
    "        self.resnet = MelResNet(res_blocks, feat_dims, compute_dims, res_out_dims, pad)\n",
    "        self.resnet_stretch = Stretch2d(total_scale, 1)\n",
    "        self.up_layers = nn.ModuleList()\n",
    "        for scale in upsample_scales:\n",
    "            k_size = (1, scale * 2 + 1)\n",
    "            padding = (0, scale)\n",
    "            stretch = Stretch2d(scale, 1)\n",
    "            conv = nn.Conv2d(1, 1, kernel_size=k_size, padding=padding, bias=False)\n",
    "            conv.weight.data.fill_(1. / k_size[1])\n",
    "            self.up_layers.append(stretch)\n",
    "            self.up_layers.append(conv)\n",
    "\n",
    "    def forward(self, m):\n",
    "        aux = self.resnet(m).unsqueeze(1)\n",
    "        aux = self.resnet_stretch(aux)\n",
    "        aux = aux.squeeze(1)\n",
    "        m = m.unsqueeze(1)\n",
    "        for f in self.up_layers: m = f(m)\n",
    "        m = m.squeeze(1)[:, :, self.indent:-self.indent]\n",
    "        return m.transpose(1, 2), aux.transpose(1, 2)\n",
    "\n",
    "\n",
    "class WaveRNN(nn.Module):\n",
    "    def __init__(self, rnn_dims, fc_dims, bits, pad, upsample_factors,\n",
    "                 feat_dims, compute_dims, res_out_dims, res_blocks,\n",
    "                 hop_length, sample_rate, mode='RAW'):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.pad = pad\n",
    "        if self.mode == 'RAW' :\n",
    "            self.n_classes = 2 ** bits\n",
    "        elif self.mode == 'MOL' :\n",
    "            self.n_classes = 30\n",
    "        else :\n",
    "            RuntimeError(\"Unknown model mode value - \", self.mode)\n",
    "\n",
    "        self.rnn_dims = rnn_dims\n",
    "        self.aux_dims = res_out_dims // 4\n",
    "        self.hop_length = hop_length\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        self.upsample = UpsampleNetwork(feat_dims, upsample_factors, compute_dims, res_blocks, res_out_dims, pad)\n",
    "        self.I = nn.Linear(feat_dims + self.aux_dims + 1, rnn_dims)\n",
    "        self.rnn1 = nn.GRU(rnn_dims, rnn_dims, batch_first=True)\n",
    "        self.rnn2 = nn.GRU(rnn_dims + self.aux_dims, rnn_dims, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_dims + self.aux_dims, fc_dims)\n",
    "        self.fc2 = nn.Linear(fc_dims + self.aux_dims, fc_dims)\n",
    "        self.fc3 = nn.Linear(fc_dims, self.n_classes)\n",
    "\n",
    "        self.step = nn.Parameter(torch.zeros(1).long(), requires_grad=False)\n",
    "        self.num_params()\n",
    "\n",
    "    def forward(self, x, mels):\n",
    "        self.step += 1\n",
    "        bsize = x.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            h1 = torch.zeros(1, bsize, self.rnn_dims).cuda()\n",
    "            h2 = torch.zeros(1, bsize, self.rnn_dims).cuda()\n",
    "        else:\n",
    "            h1 = torch.zeros(1, bsize, self.rnn_dims).cpu()\n",
    "            h2 = torch.zeros(1, bsize, self.rnn_dims).cpu()\n",
    "        mels, aux = self.upsample(mels)\n",
    "\n",
    "        aux_idx = [self.aux_dims * i for i in range(5)]\n",
    "        a1 = aux[:, :, aux_idx[0]:aux_idx[1]]\n",
    "        a2 = aux[:, :, aux_idx[1]:aux_idx[2]]\n",
    "        a3 = aux[:, :, aux_idx[2]:aux_idx[3]]\n",
    "        a4 = aux[:, :, aux_idx[3]:aux_idx[4]]\n",
    "\n",
    "        x = torch.cat([x.unsqueeze(-1), mels, a1], dim=2)\n",
    "        x = self.I(x)\n",
    "        res = x\n",
    "        x, _ = self.rnn1(x, h1)\n",
    "\n",
    "        x = x + res\n",
    "        res = x\n",
    "        x = torch.cat([x, a2], dim=2)\n",
    "        x, _ = self.rnn2(x, h2)\n",
    "\n",
    "        x = x + res\n",
    "        x = torch.cat([x, a3], dim=2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = torch.cat([x, a4], dim=2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def generate(self, mels, batched, target, overlap, mu_law, progress_callback=None):\n",
    "        mu_law = mu_law if self.mode == 'RAW' else False\n",
    "        progress_callback = progress_callback or self.gen_display\n",
    "\n",
    "        self.eval()\n",
    "        output = []\n",
    "        start = time.time()\n",
    "        rnn1 = self.get_gru_cell(self.rnn1)\n",
    "        rnn2 = self.get_gru_cell(self.rnn2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                mels = mels.cuda()\n",
    "            else:\n",
    "                mels = mels.cpu()\n",
    "            wave_len = (mels.size(-1) - 1) * self.hop_length\n",
    "            mels = self.pad_tensor(mels.transpose(1, 2), pad=self.pad, side='both')\n",
    "            mels, aux = self.upsample(mels.transpose(1, 2))\n",
    "\n",
    "            if batched:\n",
    "                mels = self.fold_with_overlap(mels, target, overlap)\n",
    "                aux = self.fold_with_overlap(aux, target, overlap)\n",
    "\n",
    "            b_size, seq_len, _ = mels.size()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                h1 = torch.zeros(b_size, self.rnn_dims).cuda()\n",
    "                h2 = torch.zeros(b_size, self.rnn_dims).cuda()\n",
    "                x = torch.zeros(b_size, 1).cuda()\n",
    "            else:\n",
    "                h1 = torch.zeros(b_size, self.rnn_dims).cpu()\n",
    "                h2 = torch.zeros(b_size, self.rnn_dims).cpu()\n",
    "                x = torch.zeros(b_size, 1).cpu()\n",
    "\n",
    "            d = self.aux_dims\n",
    "            aux_split = [aux[:, :, d * i:d * (i + 1)] for i in range(4)]\n",
    "\n",
    "            for i in range(seq_len):\n",
    "\n",
    "                m_t = mels[:, i, :]\n",
    "\n",
    "                a1_t, a2_t, a3_t, a4_t = (a[:, i, :] for a in aux_split)\n",
    "\n",
    "                x = torch.cat([x, m_t, a1_t], dim=1)\n",
    "                x = self.I(x)\n",
    "                h1 = rnn1(x, h1)\n",
    "\n",
    "                x = x + h1\n",
    "                inp = torch.cat([x, a2_t], dim=1)\n",
    "                h2 = rnn2(inp, h2)\n",
    "\n",
    "                x = x + h2\n",
    "                x = torch.cat([x, a3_t], dim=1)\n",
    "                x = F.relu(self.fc1(x))\n",
    "\n",
    "                x = torch.cat([x, a4_t], dim=1)\n",
    "                x = F.relu(self.fc2(x))\n",
    "\n",
    "                logits = self.fc3(x)\n",
    "\n",
    "                if self.mode == 'MOL':\n",
    "                    sample = sample_from_discretized_mix_logistic(logits.unsqueeze(0).transpose(1, 2))\n",
    "                    output.append(sample.view(-1))\n",
    "                    if torch.cuda.is_available():\n",
    "                        # x = torch.FloatTensor([[sample]]).cuda()\n",
    "                        x = sample.transpose(0, 1).cuda()\n",
    "                    else:\n",
    "                        x = sample.transpose(0, 1)\n",
    "\n",
    "                elif self.mode == 'RAW' :\n",
    "                    posterior = F.softmax(logits, dim=1)\n",
    "                    distrib = torch.distributions.Categorical(posterior)\n",
    "\n",
    "                    sample = 2 * distrib.sample().float() / (self.n_classes - 1.) - 1.\n",
    "                    output.append(sample)\n",
    "                    x = sample.unsqueeze(-1)\n",
    "                else:\n",
    "                    raise RuntimeError(\"Unknown model mode value - \", self.mode)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    gen_rate = (i + 1) / (time.time() - start) * b_size / 1000\n",
    "                    progress_callback(i, seq_len, b_size, gen_rate)\n",
    "\n",
    "        output = torch.stack(output).transpose(0, 1)\n",
    "        output = output.cpu().numpy()\n",
    "        output = output.astype(np.float64)\n",
    "        \n",
    "        if batched:\n",
    "            output = self.xfade_and_unfold(output, target, overlap)\n",
    "        else:\n",
    "            output = output[0]\n",
    "\n",
    "        if mu_law:\n",
    "            output = decode_mu_law(output, self.n_classes, False)\n",
    "        if hp.apply_preemphasis:\n",
    "            output = de_emphasis(output)\n",
    "\n",
    "        # Fade-out at the end to avoid signal cutting out suddenly\n",
    "        fade_out = np.linspace(1, 0, 20 * self.hop_length)\n",
    "        output = output[:wave_len]\n",
    "        output[-20 * self.hop_length:] *= fade_out\n",
    "        \n",
    "        self.train()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def gen_display(self, i, seq_len, b_size, gen_rate):\n",
    "        pbar = progbar(i, seq_len)\n",
    "        msg = f'| {pbar} {i*b_size}/{seq_len*b_size} | Batch Size: {b_size} | Gen Rate: {gen_rate:.1f}kHz | '\n",
    "        stream(msg)\n",
    "\n",
    "    def get_gru_cell(self, gru):\n",
    "        gru_cell = nn.GRUCell(gru.input_size, gru.hidden_size)\n",
    "        gru_cell.weight_hh.data = gru.weight_hh_l0.data\n",
    "        gru_cell.weight_ih.data = gru.weight_ih_l0.data\n",
    "        gru_cell.bias_hh.data = gru.bias_hh_l0.data\n",
    "        gru_cell.bias_ih.data = gru.bias_ih_l0.data\n",
    "        return gru_cell\n",
    "\n",
    "    def pad_tensor(self, x, pad, side='both'):\n",
    "        # NB - this is just a quick method i need right now\n",
    "        # i.e., it won't generalise to other shapes/dims\n",
    "        b, t, c = x.size()\n",
    "        total = t + 2 * pad if side == 'both' else t + pad\n",
    "        if torch.cuda.is_available():\n",
    "            padded = torch.zeros(b, total, c).cuda()\n",
    "        else:\n",
    "            padded = torch.zeros(b, total, c).cpu()\n",
    "        if side == 'before' or side == 'both':\n",
    "            padded[:, pad:pad + t, :] = x\n",
    "        elif side == 'after':\n",
    "            padded[:, :t, :] = x\n",
    "        return padded\n",
    "\n",
    "    def fold_with_overlap(self, x, target, overlap):\n",
    "        _, total_len, features = x.size()\n",
    "\n",
    "        # Calculate variables needed\n",
    "        num_folds = (total_len - overlap) // (target + overlap)\n",
    "        extended_len = num_folds * (overlap + target) + overlap\n",
    "        remaining = total_len - extended_len\n",
    "\n",
    "        # Pad if some time steps poking out\n",
    "        if remaining != 0:\n",
    "            num_folds += 1\n",
    "            padding = target + 2 * overlap - remaining\n",
    "            x = self.pad_tensor(x, padding, side='after')\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            folded = torch.zeros(num_folds, target + 2 * overlap, features).cuda()\n",
    "        else:\n",
    "            folded = torch.zeros(num_folds, target + 2 * overlap, features).cpu()\n",
    "\n",
    "        # Get the values for the folded tensor\n",
    "        for i in range(num_folds):\n",
    "            start = i * (target + overlap)\n",
    "            end = start + target + 2 * overlap\n",
    "            folded[i] = x[:, start:end, :]\n",
    "\n",
    "        return folded\n",
    "\n",
    "    def xfade_and_unfold(self, y, target, overlap):\n",
    "\n",
    "        num_folds, length = y.shape\n",
    "        target = length - 2 * overlap\n",
    "        total_len = num_folds * (target + overlap) + overlap\n",
    "\n",
    "        # Need some silence for the rnn warmup\n",
    "        silence_len = overlap // 2\n",
    "        fade_len = overlap - silence_len\n",
    "        silence = np.zeros((silence_len), dtype=np.float64)\n",
    "\n",
    "        # Equal power crossfade\n",
    "        t = np.linspace(-1, 1, fade_len, dtype=np.float64)\n",
    "        fade_in = np.sqrt(0.5 * (1 + t))\n",
    "        fade_out = np.sqrt(0.5 * (1 - t))\n",
    "\n",
    "        # Concat the silence to the fades\n",
    "        fade_in = np.concatenate([silence, fade_in])\n",
    "        fade_out = np.concatenate([fade_out, silence])\n",
    "\n",
    "        # Apply the gain to the overlap samples\n",
    "        y[:, :overlap] *= fade_in\n",
    "        y[:, -overlap:] *= fade_out\n",
    "\n",
    "        unfolded = np.zeros((total_len), dtype=np.float64)\n",
    "\n",
    "        # Loop to add up all the samples\n",
    "        for i in range(num_folds):\n",
    "            start = i * (target + overlap)\n",
    "            end = start + target + 2 * overlap\n",
    "            unfolded[start:end] += y[i]\n",
    "\n",
    "        return unfolded\n",
    "\n",
    "    def get_step(self) :\n",
    "        return self.step.data.item()\n",
    "\n",
    "    def checkpoint(self, model_dir, optimizer) :\n",
    "        k_steps = self.get_step() // 1000\n",
    "        self.save(model_dir.joinpath(\"checkpoint_%dk_steps.pt\" % k_steps), optimizer)\n",
    "\n",
    "    def log(self, path, msg) :\n",
    "        with open(path, 'a') as f:\n",
    "            print(msg, file=f)\n",
    "\n",
    "    def load(self, path, optimizer) :\n",
    "        checkpoint = torch.load(path)\n",
    "        if \"optimizer_state\" in checkpoint:\n",
    "            self.load_state_dict(checkpoint[\"model_state\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        else:\n",
    "            # Backwards compatibility\n",
    "            self.load_state_dict(checkpoint)\n",
    "\n",
    "    def save(self, path, optimizer) :\n",
    "        torch.save({\n",
    "            \"model_state\": self.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "        }, path)\n",
    "\n",
    "    def num_params(self, print_out=True):\n",
    "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
    "        if print_out :\n",
    "            print('Trainable Parameters: %.3fM' % parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f48e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 4.481M\n"
     ]
    }
   ],
   "source": [
    "model = WaveRNN(\n",
    "        rnn_dims=hparams.voc_rnn_dims,\n",
    "        fc_dims=hparams.voc_fc_dims,\n",
    "        bits=hparams.bits,\n",
    "        pad=hparams.voc_pad,\n",
    "        upsample_factors=hparams.voc_upsample_factors,\n",
    "        feat_dims=hparams.num_mels,\n",
    "        compute_dims=hparams.voc_compute_dims,\n",
    "        res_out_dims=hparams.voc_res_out_dims,\n",
    "        res_blocks=hparams.voc_res_blocks,\n",
    "        hop_length=hparams.hop_length,\n",
    "        sample_rate=hparams.sample_rate,\n",
    "        mode=hparams.voc_mode\n",
    "    )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71754d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af429869",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for p in optimizer.param_groups: p[\"lr\"] = hparams.voc_lr\n",
    "loss_func = F.cross_entropy if model.mode == \"RAW\" else discretized_mix_logistic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4422e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VocoderDataset(data)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89f7280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "limt = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31d7da2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/10] 10/10 [==================================================] 100% - loss: 5.5314 \n",
      "Epoch [02/10] 10/10 [==================================================] 100% - loss: 5.5087 \n",
      "Epoch [03/10] 10/10 [==================================================] 100% - loss: 5.4905 \n",
      "Epoch [04/10] 10/10 [==================================================] 100% - loss: 5.3704 \n",
      "Epoch [05/10] 10/10 [==================================================] 100% - loss: 5.3361 \n",
      "Epoch [06/10] 10/10 [==================================================] 100% - loss: 5.4237 \n",
      "Epoch [07/10] 10/10 [==================================================] 100% - loss: 5.4384 \n",
      "Epoch [08/10] 10/10 [==================================================] 100% - loss: 5.4069 \n",
      "Epoch [09/10] 10/10 [==================================================] 100% - loss: 5.3878 \n"
     ]
    }
   ],
   "source": [
    "bsize = len(data_loader) if limt==-1 else limt\n",
    "for epoch in range(1, epochs):\n",
    "    data_loader = DataLoader(dataset, hparams.voc_batch_size, shuffle=True, num_workers=2, collate_fn=collate_vocoder)\n",
    "    running_loss = 0.\n",
    "    \n",
    "    i = 0\n",
    "    p = f\"Epoch [{pretty_print(epoch, epochs)}/{epochs}] {pretty_print(i, bsize)}/{bsize}\"\n",
    "    loadbar(i, bsize, p, length=50)\n",
    "    for idx, (x, y, m) in enumerate(data_loader, 1):\n",
    "        \n",
    "        if idx > bsize: break\n",
    "        \n",
    "        if torch.cuda.is_available(): x, m, y = x.cuda(), m.cuda(), y.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = model(x, m)\n",
    "        if model.mode == 'RAW': y_hat = y_hat.transpose(1, 2).unsqueeze(-1)\n",
    "        elif model.mode == 'MOL': y = y.float()\n",
    "        y = y.unsqueeze(-1)\n",
    "\n",
    "        # Backward pass\n",
    "        loss = loss_func(y_hat, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / idx\n",
    "\n",
    "        step = model.get_step()\n",
    "        \n",
    "        p = f\"Epoch [{pretty_print(epoch, epochs)}/{epochs}] {pretty_print(i+1, bsize)}/{bsize}\"\n",
    "        s = f\"- loss: {loss:.4f}\"\n",
    "        loadbar(i+1, bsize, p, s, length=50)\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "#         print(epoch, idx, loss)\n",
    "            \n",
    "#         break\n",
    "\n",
    "\n",
    "\n",
    "#     gen_testset(model, test_loader, hp.voc_gen_at_checkpoint, hp.voc_gen_batched, hp.voc_target, hp.voc_overlap, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f247d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
